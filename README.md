# ğŸ¤– Sistema de AsesorÃ­a Inteligente con IA Local

Este backend gestiona solicitudes de clientes desde un formulario web, las procesa mediante una IA local para generar respuestas motivadoras y las distribuye en mÃºltiples plataformas en tiempo real.

## ğŸš€ Funcionalidades
- **IA Local (Ollama):** Utiliza el modelo `Qwen2.5-3B` para resumir y responder con tono empÃ¡tico y profesional.
- **Multicanal:** - ğŸ“Š Registro automÃ¡tico en **Google Sheets**.
  - ğŸ“ Respaldo local en archivo **CSV**.
  - ğŸ“± Notificaciones instantÃ¡neas vÃ­a **Telegram Bot**.
- **AsÃ­ncrono:** Procesamiento en hilos (`threading`) para no hacer esperar al usuario en la web.

## ğŸ› ï¸ TecnologÃ­as
- **Backend:** Python + Flask.
- **IA:** Ollama (Modelo Qwen 2.5 3B).
- **Integraciones:** Google Apps Script API, Telegram API.
- **Servidor:** Linux (Ubuntu/Debian) con Nginx y Systemd.

## ğŸ“‹ Requisitos
- Ollama instalado y corriendo.
- Modelo descargado: `ollama pull qwen2.5:3b`.
- Dependencias de Python: `pip install flask requests`.

## âš™ï¸ ConfiguraciÃ³n del Backend
El servicio corre bajo `systemd` para asegurar alta disponibilidad:
- **Unidad:** `asesoria-backend.service`
- **Puerto:** 5000 (Proxy pass con Nginx).